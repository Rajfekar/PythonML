{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEu3e7FNuww9CsOBRtN+29",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee8173ed0ea6467d9ca299f53bba21f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52dff315e4e8416a9a5acf6eac02865b",
              "IPY_MODEL_44fe892908914362b3f61d5080d179fa",
              "IPY_MODEL_9d8cf1518e4d40158dae3148df5c1567"
            ],
            "layout": "IPY_MODEL_408f6e5731a540a78f0f7b674da1cd20"
          }
        },
        "52dff315e4e8416a9a5acf6eac02865b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a560f15e6f4733ab431181ddba20da",
            "placeholder": "​",
            "style": "IPY_MODEL_9afe2ffe50814e05a19a35cd1e889f41",
            "value": "Batches: 100%"
          }
        },
        "44fe892908914362b3f61d5080d179fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff8ed7f5c9f14daaac7d300dd7ece880",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d863f5c2942d4653876c48b9286140bb",
            "value": 21
          }
        },
        "9d8cf1518e4d40158dae3148df5c1567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe30768777f247488bc6f22e0ef0ae22",
            "placeholder": "​",
            "style": "IPY_MODEL_0886f79eb72f4a43acd995655e64cbd9",
            "value": " 21/21 [01:09&lt;00:00,  1.04s/it]"
          }
        },
        "408f6e5731a540a78f0f7b674da1cd20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2a560f15e6f4733ab431181ddba20da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9afe2ffe50814e05a19a35cd1e889f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff8ed7f5c9f14daaac7d300dd7ece880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d863f5c2942d4653876c48b9286140bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe30768777f247488bc6f22e0ef0ae22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0886f79eb72f4a43acd995655e64cbd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f70ad5a3f94c888dccad571a5bbb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc82eb3eed6d470e906695447a2f5233",
              "IPY_MODEL_28d48baf57d74a1489e609b29849f1fb",
              "IPY_MODEL_4ae34a53b60a417098c9968282f61db1"
            ],
            "layout": "IPY_MODEL_f0adf230df49437f996f5b18769edf84"
          }
        },
        "bc82eb3eed6d470e906695447a2f5233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1a4804bd06472bb201ceadebe8af5c",
            "placeholder": "​",
            "style": "IPY_MODEL_662e9cc9cebe4143b9b4971aedd8d7e4",
            "value": "Batches: 100%"
          }
        },
        "28d48baf57d74a1489e609b29849f1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8977219cdd9e4421b210a8c0c36574a0",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0833ff6297fc491297acf7fa47c0df6a",
            "value": 21
          }
        },
        "4ae34a53b60a417098c9968282f61db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25640760af9a4c368f0fb69f89a57f2c",
            "placeholder": "​",
            "style": "IPY_MODEL_04aa83f8fd32436f8439b83d1592e562",
            "value": " 21/21 [01:12&lt;00:00,  1.03s/it]"
          }
        },
        "f0adf230df49437f996f5b18769edf84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1a4804bd06472bb201ceadebe8af5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662e9cc9cebe4143b9b4971aedd8d7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8977219cdd9e4421b210a8c0c36574a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0833ff6297fc491297acf7fa47c0df6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25640760af9a4c368f0fb69f89a57f2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04aa83f8fd32436f8439b83d1592e562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajfekar/PythonML/blob/main/reranking_raj_bi_encoder_cross_encoder(bert).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers faiss-cpu pandas rapidfuzz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xe6xm7A142j",
        "outputId": "295f725b-c405-45f7-f5a6-c085b7e5bfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/3.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/3.2 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343,
          "referenced_widgets": [
            "ee8173ed0ea6467d9ca299f53bba21f2",
            "52dff315e4e8416a9a5acf6eac02865b",
            "44fe892908914362b3f61d5080d179fa",
            "9d8cf1518e4d40158dae3148df5c1567",
            "408f6e5731a540a78f0f7b674da1cd20",
            "d2a560f15e6f4733ab431181ddba20da",
            "9afe2ffe50814e05a19a35cd1e889f41",
            "ff8ed7f5c9f14daaac7d300dd7ece880",
            "d863f5c2942d4653876c48b9286140bb",
            "fe30768777f247488bc6f22e0ef0ae22",
            "0886f79eb72f4a43acd995655e64cbd9"
          ]
        },
        "id": "vnHsfPvny8MO",
        "outputId": "ed641228-5656-4ae7-8bdb-c669271a41a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee8173ed0ea6467d9ca299f53bba21f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPT: 78597  |  score: 0.9600\n",
            "snippet: 78597 Lung perfusion differential RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provider performs pulmonary perfusion, a nuclear scan test that evaluates the flow of blood within the patient’s lungs. The aim is to per\n",
            "--------------------------------------------------------------------------------\n",
            "CPT: 0042T  |  score: 0.9103\n",
            "snippet: 0042T Ct perfusion w/contrast cbf RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider obtains a measurement of regional cerebral blood flow through analysis of computed tomography (CT) scans by taking sequential images of sections of the brain \n",
            "--------------------------------------------------------------------------------\n",
            "CPT: 78580  |  score: 0.9004\n",
            "snippet: 78580 Lung perfusion imaging RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provider performs a nuclear perfusion imaging test to evaluate the circulation of blood within the patient’s lungs. He does this to identify t\n",
            "--------------------------------------------------------------------------------\n",
            "CPT: 78582  |  score: 0.8780\n",
            "snippet: 78582 Lung ventilat&perfus imaging RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provider performs both pulmonary ventilation and perfusion imaging in a nuclear scan test that evaluates the circulation of air and bloo\n",
            "--------------------------------------------------------------------------------\n",
            "CPT: 78598  |  score: 0.8188\n",
            "snippet: 78598 Lung perf&ventilat diferentl RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provider performs both pulmonary ventilation and perfusion nuclear scan tests that evaluate the circulation of air and blood within the \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "csv_path = '/content/merged_cpt_data - merged_cpt_data.csv.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df['Summary_clean'] = (\n",
        "    df['Summary'].astype(str)\n",
        "      .str.replace(r'(?i)^Summary\\s*', '', regex=True)\n",
        "      .str.replace(r'\\\\n', ' ', regex=True)\n",
        "      .str.replace('\\n', ' ', regex=False)\n",
        "      .str.replace(r'\\s+', ' ', regex=True)\n",
        "      .str.strip()\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "df[\"merged_text\"] = (\n",
        "    (df[\"CPT_Code\"].astype(str) + \" \") +\n",
        "    df[\"Desc\"].astype(str) + \" \" +\n",
        "    df[\"Category\"].astype(str) + \" \" +\n",
        "    df[\"Summary_clean\"].astype(str)\n",
        ")\n",
        "\n",
        "summaries = df[\"merged_text\"].astype(str).tolist()\n",
        "ids = list(df['CPT_Code'].astype(str).tolist())\n",
        "\n",
        "embed_model_name = 'all-MiniLM-L6-v2'\n",
        "reranker_model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "\n",
        "embed_model = SentenceTransformer(embed_model_name, device=device)\n",
        "reranker = CrossEncoder(reranker_model_name, device=device)\n",
        "\n",
        "embeddings = embed_model.encode(summaries, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
        "faiss.normalize_L2(embeddings)\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(embeddings)\n",
        "faiss.write_index(index, \"mergedtext_faiss.index\")\n",
        "np.save(\"merged_summaries.npy\", np.array(summaries))\n",
        "np.save(\"merged_ids.npy\", np.array(ids))\n",
        "\n",
        "def normalize_code(s):\n",
        "    if s is None:\n",
        "        return None\n",
        "    return re.sub(r'[\\s\\-]', '', str(s)).upper()\n",
        "\n",
        "TOKEN_RE = re.compile(r'\\b[A-Za-z0-9]+\\b')\n",
        "CONTAINS_DIGIT_RE = re.compile(r'\\d')\n",
        "\n",
        "normalized_ids = [normalize_code(x) for x in ids]\n",
        "code_to_index = {nid: i for i, nid in enumerate(normalized_ids)}\n",
        "code_list = list(code_to_index.keys())\n",
        "\n",
        "FUZZY_THRESHOLD = 90\n",
        "SEMANTIC_CONF_THRESHOLD = 0.80\n",
        "CODE_DESC_MISMATCH_SCORE = 0.90\n",
        "DEMOTION_FACTOR = 0.35\n",
        "\n",
        "def search_and_rerank_combined(\n",
        "    query: str,\n",
        "    top_k: int = 200,\n",
        "    rerank_k: int = 50,\n",
        "    reranker_batch: int = 32,\n",
        "    use_fuzzy_for_code: bool = True,\n",
        "    fuzzy_threshold: int = FUZZY_THRESHOLD,\n",
        "    semantic_conf_threshold: float = SEMANTIC_CONF_THRESHOLD,\n",
        "    code_mismatch_score: float = CODE_DESC_MISMATCH_SCORE,\n",
        "    demotion_factor: float = DEMOTION_FACTOR\n",
        "):\n",
        "    if not query:\n",
        "        return []\n",
        "\n",
        "    tokens = TOKEN_RE.findall(query)\n",
        "    token_norms = [normalize_code(t) for t in tokens if t]\n",
        "\n",
        "    candidate_code_token = None\n",
        "    candidate_token_original = None\n",
        "    for i, orig_t in enumerate(tokens):\n",
        "        t = token_norms[i] if i < len(token_norms) else normalize_code(orig_t)\n",
        "        if not t:\n",
        "            continue\n",
        "        if CONTAINS_DIGIT_RE.search(t) and 1 <= len(t) <= 12:\n",
        "            candidate_code_token = t\n",
        "            candidate_token_original = orig_t\n",
        "            break\n",
        "\n",
        "    if len(tokens) == 1 and candidate_code_token:\n",
        "        code_norm = candidate_code_token\n",
        "        if code_norm in code_to_index:\n",
        "            idx = code_to_index[code_norm]\n",
        "            return [(ids[idx], summaries[idx], 1.0)]\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    matched_code_idx = None\n",
        "    matched_code_norm = None\n",
        "    matched_code_conf = 0.0\n",
        "    if use_fuzzy_for_code and candidate_code_token:\n",
        "        match, score, _ = process.extractOne(candidate_code_token, code_list, scorer=fuzz.ratio)\n",
        "        if score >= fuzzy_threshold:\n",
        "            matched_code_norm = match\n",
        "            matched_code_conf = score / 100.0\n",
        "            matched_code_idx = code_to_index[match]\n",
        "\n",
        "    desc_query = query.strip()\n",
        "    if candidate_code_token and len(tokens) > 1:\n",
        "        if candidate_token_original:\n",
        "            tmp = re.sub(r'\\b' + re.escape(candidate_token_original) + r'\\b', '', desc_query, flags=re.IGNORECASE)\n",
        "            desc_query = re.sub(r'\\s+', ' ', tmp).strip()\n",
        "        else:\n",
        "            tmp = re.sub(r'\\b' + re.escape(candidate_code_token) + r'\\b', '', desc_query, flags=re.IGNORECASE)\n",
        "            desc_query = re.sub(r'\\s+', ' ', tmp).strip()\n",
        "\n",
        "    if not desc_query:\n",
        "        if matched_code_idx is not None:\n",
        "            if matched_code_norm == candidate_code_token:\n",
        "                return [(ids[matched_code_idx], summaries[matched_code_idx], 1.0)]\n",
        "            else:\n",
        "                return [(ids[matched_code_idx], summaries[matched_code_idx], max(0.95, matched_code_conf))]\n",
        "        return []\n",
        "\n",
        "    q_emb = embed_model.encode([desc_query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    idxs = I[0].tolist()\n",
        "    candidates = [summaries[i] for i in idxs]\n",
        "    candidate_ids = [ids[i] for i in idxs]\n",
        "\n",
        "    pairs = [[desc_query, cand] for cand in candidates]\n",
        "    scores = []\n",
        "    for start in range(0, len(pairs), reranker_batch):\n",
        "        batch_pairs = pairs[start:start+reranker_batch]\n",
        "        batch_scores = reranker.predict(batch_pairs)\n",
        "        batch_scores = torch.tensor(batch_scores, dtype=torch.float32)\n",
        "        batch_probs = torch.sigmoid(batch_scores).tolist()\n",
        "        scores.extend(batch_probs)\n",
        "\n",
        "    combined = list(zip(candidate_ids, candidates, [float(s) for s in scores]))\n",
        "    scores_by_id = {cid: sc for cid, _, sc in combined}\n",
        "\n",
        "    code_id = None\n",
        "    code_text = None\n",
        "    if matched_code_idx is not None:\n",
        "        code_id = ids[matched_code_idx]\n",
        "        code_text = summaries[matched_code_idx]\n",
        "    elif candidate_code_token and candidate_code_token in code_to_index:\n",
        "        matched_code_idx = code_to_index[candidate_code_token]\n",
        "        code_id = ids[matched_code_idx]\n",
        "        code_text = summaries[matched_code_idx]\n",
        "\n",
        "    final_list = []\n",
        "    if code_id:\n",
        "        semantic_score_for_code = float(scores_by_id.get(code_id, 0.0))\n",
        "        if semantic_score_for_code >= semantic_conf_threshold:\n",
        "            code_combined_score = 1.0\n",
        "        else:\n",
        "            code_combined_score = code_mismatch_score\n",
        "        final_list.append((code_id, code_text, float(code_combined_score)))\n",
        "\n",
        "    for cid, txt, sc in combined:\n",
        "        if cid == code_id:\n",
        "            continue\n",
        "        adj_score = float(sc)\n",
        "        if code_id:\n",
        "            adj_score = adj_score * demotion_factor\n",
        "        final_list.append((cid, txt, adj_score))\n",
        "\n",
        "    final_list.sort(key=lambda x: x[2], reverse=True)\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for cid, txt, sc in final_list:\n",
        "        if cid in seen:\n",
        "            continue\n",
        "        seen.add(cid)\n",
        "        out.append((cid, txt, float(sc)))\n",
        "        if len(out) >= rerank_k:\n",
        "            break\n",
        "\n",
        "    return out\n",
        "\n",
        "query = \"perfusion\"\n",
        "results = search_and_rerank_combined(query, top_k=20, rerank_k=5, reranker_batch=32)\n",
        "\n",
        "for cid, text, score in results:\n",
        "    print(f\"CPT: {cid}  |  score: {score:.4f}\")\n",
        "    print(\"snippet:\", text[:250].replace(\"\\n\", \" \"))\n",
        "    print(\"-\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build_and_save.py\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "\n",
        "CSV_PATH = \"/content/merged_cpt_data - merged_cpt_data.csv.csv\"   # change if needed\n",
        "OUT_DIR = \"./data\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# clean summary\n",
        "df[\"Summary_clean\"] = (\n",
        "    df[\"Summary\"].astype(str)\n",
        "      .str.replace(r'(?i)^Summary\\s*', '', regex=True)\n",
        "      .str.replace(r'\\\\n', ' ', regex=True)\n",
        "      .str.replace('\\n', ' ', regex=False)\n",
        "      .str.replace(r'\\s+', ' ', regex=True)\n",
        "      .str.strip()\n",
        ")\n",
        "\n",
        "# build merged text (you used merged_text earlier)\n",
        "df[\"merged_text\"] = (\n",
        "    (df[\"CPT_Code\"].astype(str) + \" \") +\n",
        "    df[\"Desc\"].astype(str) + \" \" +\n",
        "    df[\"Category\"].astype(str) + \" \" +\n",
        "    df[\"Summary_clean\"].astype(str)\n",
        ")\n",
        "\n",
        "# prepare lists\n",
        "ids = df[\"CPT_Code\"].astype(str).tolist()\n",
        "summaries = df[\"merged_text\"].astype(str).tolist()\n",
        "\n",
        "# load embed model and encode\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME, device=DEVICE)\n",
        "embeddings = embed_model.encode(summaries, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
        "\n",
        "# normalize and build FAISS index (inner product on normalized vectors => cosine)\n",
        "faiss.normalize_L2(embeddings)\n",
        "dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatIP(dim)\n",
        "index.add(embeddings)\n",
        "\n",
        "# save artifacts\n",
        "np.save(os.path.join(OUT_DIR, \"embeddings.npy\"), embeddings)\n",
        "np.save(os.path.join(OUT_DIR, \"summaries.npy\"), np.array(summaries))\n",
        "pd.DataFrame({\"CPT_Code\": ids, \"merged_text\": summaries}).to_csv(os.path.join(OUT_DIR, \"ids.csv\"), index=False)\n",
        "faiss.write_index(index, os.path.join(OUT_DIR, \"mergedtext_faiss.index\"))\n",
        "\n",
        "print(\"Saved artifacts to\", OUT_DIR)\n",
        "print(\"ntotal in index:\", index.ntotal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "52f70ad5a3f94c888dccad571a5bbb89",
            "bc82eb3eed6d470e906695447a2f5233",
            "28d48baf57d74a1489e609b29849f1fb",
            "4ae34a53b60a417098c9968282f61db1",
            "f0adf230df49437f996f5b18769edf84",
            "de1a4804bd06472bb201ceadebe8af5c",
            "662e9cc9cebe4143b9b4971aedd8d7e4",
            "8977219cdd9e4421b210a8c0c36574a0",
            "0833ff6297fc491297acf7fa47c0df6a",
            "25640760af9a4c368f0fb69f89a57f2c",
            "04aa83f8fd32436f8439b83d1592e562"
          ]
        },
        "id": "BoiQ6LSJ4Zg4",
        "outputId": "0993c6cc-05cc-4cf2-e7b4-a08aea542261"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/21 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f70ad5a3f94c888dccad571a5bbb89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifacts to ./data\n",
            "ntotal in index: 1321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load_and_search.py\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "from rapidfuzz import process, fuzz\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "# config & paths (adjust)\n",
        "OUT_DIR = \"./data\"\n",
        "EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
        "RERANKER_MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "EMBEDDINGS_PATH = os.path.join(OUT_DIR, \"embeddings.npy\")\n",
        "SUMMARIES_PATH = os.path.join(OUT_DIR, \"summaries.npy\")\n",
        "IDS_CSV_PATH = os.path.join(OUT_DIR, \"ids.csv\")\n",
        "FAISS_INDEX_PATH = os.path.join(OUT_DIR, \"mergedtext_faiss.index\")\n",
        "\n",
        "# load artifacts\n",
        "embeddings = np.load(EMBEDDINGS_PATH)\n",
        "summaries = np.load(SUMMARIES_PATH, allow_pickle=True).tolist()\n",
        "ids_df = pd.read_csv(IDS_CSV_PATH)\n",
        "ids = ids_df[\"CPT_Code\"].astype(str).tolist()\n",
        "\n",
        "# load or recreate FAISS index\n",
        "if os.path.exists(FAISS_INDEX_PATH):\n",
        "    index = faiss.read_index(FAISS_INDEX_PATH)\n",
        "else:\n",
        "    faiss.normalize_L2(embeddings)\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(embeddings)\n",
        "\n",
        "# models\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME, device=DEVICE)\n",
        "reranker = CrossEncoder(RERANKER_MODEL_NAME, device=DEVICE)\n",
        "\n",
        "# helpers\n",
        "def normalize_code(s: Optional[str]) -> Optional[str]:\n",
        "    if s is None:\n",
        "        return None\n",
        "    return re.sub(r'[\\s\\-]', '', str(s)).upper()\n",
        "\n",
        "TOKEN_RE = re.compile(r'\\b[A-Za-z0-9]+\\b')\n",
        "CONTAINS_DIGIT_RE = re.compile(r'\\d')\n",
        "\n",
        "normalized_ids = [normalize_code(x) for x in ids]\n",
        "code_to_index = {nid: i for i, nid in enumerate(normalized_ids)}\n",
        "code_list = list(code_to_index.keys())\n",
        "\n",
        "# thresholds\n",
        "FUZZY_THRESHOLD = 90\n",
        "SEMANTIC_CONF_THRESHOLD = 0.80\n",
        "CODE_DESC_MISMATCH_SCORE = 0.90\n",
        "DEMOTION_FACTOR = 0.35\n",
        "\n",
        "def search_loaded(\n",
        "    query: str,\n",
        "    top_k: int = 200,\n",
        "    rerank_k: int = 50,\n",
        "    reranker_batch: int = 32,\n",
        "    use_fuzzy_for_code: bool = True\n",
        ") -> List[Tuple[str, str, float]]:\n",
        "    if not query or not query.strip():\n",
        "        return []\n",
        "\n",
        "    tokens = TOKEN_RE.findall(query)\n",
        "    token_norms = [normalize_code(t) for t in tokens if t]\n",
        "\n",
        "    # detect first token containing a digit -> candidate code\n",
        "    candidate_code_token = None\n",
        "    candidate_token_original = None\n",
        "    for i, orig_t in enumerate(tokens):\n",
        "        t = token_norms[i] if i < len(token_norms) else normalize_code(orig_t)\n",
        "        if not t:\n",
        "            continue\n",
        "        if CONTAINS_DIGIT_RE.search(t) and 1 <= len(t) <= 12:\n",
        "            candidate_code_token = t\n",
        "            candidate_token_original = orig_t\n",
        "            break\n",
        "\n",
        "    # fast path: code-only\n",
        "    if len(tokens) == 1 and candidate_code_token:\n",
        "        if candidate_code_token in code_to_index:\n",
        "            idx = code_to_index[candidate_code_token]\n",
        "            return [(ids[idx], summaries[idx], 1.0)]\n",
        "        else:\n",
        "            return []\n",
        "\n",
        "    # fuzzy code lookup\n",
        "    matched_code_idx = None\n",
        "    matched_code_norm = None\n",
        "    matched_code_conf = 0.0\n",
        "    if use_fuzzy_for_code and candidate_code_token:\n",
        "        match, score, _ = process.extractOne(candidate_code_token, code_list, scorer=fuzz.ratio)\n",
        "        if score >= FUZZY_THRESHOLD:\n",
        "            matched_code_norm = match\n",
        "            matched_code_conf = score / 100.0\n",
        "            matched_code_idx = code_to_index[match]\n",
        "\n",
        "    # remove code token from query to form description-only query\n",
        "    desc_query = query.strip()\n",
        "    if candidate_code_token and len(tokens) > 1:\n",
        "        if candidate_token_original:\n",
        "            tmp = re.sub(r'\\b' + re.escape(candidate_token_original) + r'\\b', '', desc_query, flags=re.IGNORECASE)\n",
        "            desc_query = re.sub(r'\\s+', ' ', tmp).strip()\n",
        "        else:\n",
        "            tmp = re.sub(r'\\b' + re.escape(candidate_code_token) + r'\\b', '', desc_query, flags=re.IGNORECASE)\n",
        "            desc_query = re.sub(r'\\s+', ' ', tmp).strip()\n",
        "\n",
        "    # if no desc left -> return matched code\n",
        "    if not desc_query:\n",
        "        if matched_code_idx is not None:\n",
        "            if matched_code_norm == candidate_code_token:\n",
        "                return [(ids[matched_code_idx], summaries[matched_code_idx], 1.0)]\n",
        "            else:\n",
        "                return [(ids[matched_code_idx], summaries[matched_code_idx], max(0.95, matched_code_conf))]\n",
        "        return []\n",
        "\n",
        "    # semantic retrieval on desc_query\n",
        "    q_emb = embed_model.encode([desc_query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(q_emb)\n",
        "    D, I = index.search(q_emb, top_k)\n",
        "    idxs = I[0].tolist()\n",
        "    candidates = [summaries[i] for i in idxs]\n",
        "    candidate_ids = [ids[i] for i in idxs]\n",
        "\n",
        "    # reranker scoring\n",
        "    pairs = [[desc_query, cand] for cand in candidates]\n",
        "    scores = []\n",
        "    for start in range(0, len(pairs), reranker_batch):\n",
        "        batch_pairs = pairs[start:start+reranker_batch]\n",
        "        batch_scores = reranker.predict(batch_pairs)\n",
        "        batch_scores = torch.tensor(batch_scores, dtype=torch.float32)\n",
        "        batch_probs = torch.sigmoid(batch_scores).tolist()\n",
        "        scores.extend(batch_probs)\n",
        "\n",
        "    combined = list(zip(candidate_ids, candidates, [float(s) for s in scores]))\n",
        "    scores_by_id = {cid: sc for cid, _, sc in combined}\n",
        "\n",
        "    # resolve code doc (from fuzzy or exact map)\n",
        "    code_id = None\n",
        "    code_text = None\n",
        "    if matched_code_idx is not None:\n",
        "        code_id = ids[matched_code_idx]\n",
        "        code_text = summaries[matched_code_idx]\n",
        "    elif candidate_code_token and candidate_code_token in code_to_index:\n",
        "        matched_code_idx = code_to_index[candidate_code_token]\n",
        "        code_id = ids[matched_code_idx]\n",
        "        code_text = summaries[matched_code_idx]\n",
        "\n",
        "    final_list = []\n",
        "    if code_id:\n",
        "        semantic_score_for_code = float(scores_by_id.get(code_id, 0.0))\n",
        "        if semantic_score_for_code >= SEMANTIC_CONF_THRESHOLD:\n",
        "            code_combined_score = 1.0\n",
        "        else:\n",
        "            code_combined_score = CODE_DESC_MISMATCH_SCORE\n",
        "        final_list.append((code_id, code_text, float(code_combined_score)))\n",
        "\n",
        "    for cid, txt, sc in combined:\n",
        "        if cid == code_id:\n",
        "            continue\n",
        "        adj_score = float(sc)\n",
        "        if code_id:\n",
        "            adj_score = adj_score * DEMOTION_FACTOR\n",
        "        final_list.append((cid, txt, adj_score))\n",
        "\n",
        "    final_list.sort(key=lambda x: x[2], reverse=True)\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for cid, txt, sc in final_list:\n",
        "        if cid in seen:\n",
        "            continue\n",
        "        seen.add(cid)\n",
        "        out.append((cid, txt, float(sc)))\n",
        "        if len(out) >= rerank_k:\n",
        "            break\n",
        "\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "pszo7kXQ4_pA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    q_list = [\n",
        "        \"42324205\",\n",
        "        \"A9557\",\n",
        "        \"93980 Echo transthoracic\",\n",
        "        \"perfusion\"\n",
        "    ]\n",
        "    for q in q_list:\n",
        "        print(\"\\nQuery:\", q)\n",
        "        res = search_loaded(q, top_k=20, rerank_k=5, reranker_batch=32)\n",
        "        for cid, text, score in res:\n",
        "            print(f\"  {cid}  score={score:.4f}  snippet={text[:120].replace(chr(10),' ')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucp5nbG85H-Q",
        "outputId": "d107cde3-b844-4c17-ca5f-aeba75d0ba4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: 42324205\n",
            "\n",
            "Query: A9557\n",
            "  A9557  score=1.0000  snippet=A9557 Tc99m bicisate RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES nan\n",
            "\n",
            "Query: 93980 Echo transthoracic\n",
            "  93980  score=0.9000  snippet=93980 Penile vascular study RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider performs a complete study of the p\n",
            "  93303  score=0.3499  snippet=93303 Echo transthoracic RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider performs a complete transthoracic ech\n",
            "  93304  score=0.3499  snippet=93304 Echo transthoracic RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider performs a limited or follow–up trans\n",
            "  93308  score=0.3487  snippet=93308 Tte f-up or lmtd RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider performs a limited or follow–up transth\n",
            "  76506  score=0.0589  snippet=76506 Echo exam of head RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider performs a noninvasive diagnostic imag\n",
            "\n",
            "Query: perfusion\n",
            "  78597  score=0.9600  snippet=78597 Lung perfusion differential RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provide\n",
            "  0042T  score=0.9103  snippet=0042T Ct perfusion w/contrast cbf RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES The provider obtains a measurement of reg\n",
            "  78580  score=0.9004  snippet=78580 Lung perfusion imaging RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provider per\n",
            "  78582  score=0.8780  snippet=78582 Lung ventilat&perfus imaging RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provid\n",
            "  78598  score=0.8188  snippet=78598 Lung perf&ventilat diferentl RADIOLOGY AND CERTAIN OTHER IMAGING SERVICES In this diagnostic procedure, the provid\n"
          ]
        }
      ]
    }
  ]
}